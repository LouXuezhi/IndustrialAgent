"""
é‡æ’åºæ¨¡å—ï¼šä½¿ç”¨ Cross-Encoder å¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åºï¼Œæå‡æ£€ç´¢è´¨é‡ã€‚
æ”¯æŒç¼“å­˜æœºåˆ¶ä»¥æå‡é‡å¤æŸ¥è¯¢çš„æ€§èƒ½ã€‚
"""
import hashlib
import json
import logging
from dataclasses import replace
from typing import Any

logger = logging.getLogger(__name__)


class Reranker:
    """
    é‡æ’åºå™¨ï¼šä½¿ç”¨ Cross-Encoder æ¨¡å‹å¯¹æ£€ç´¢ç»“æœé‡æ–°æ’åºã€‚
    
    Cross-Encoder é€šè¿‡åŒæ—¶ç¼–ç æŸ¥è¯¢å’Œæ–‡æ¡£ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°ç›¸å…³æ€§ã€‚
    """
    
    def __init__(self, model_name: str | None = None, enable: bool = True, enable_cache: bool = True):
        """
        åˆå§‹åŒ–é‡æ’åºå™¨ã€‚
        
        Args:
            model_name: é‡æ’åºæ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ–‡æ¨¡å‹ BAAI/bge-reranker-base
            enable: æ˜¯å¦å¯ç”¨é‡æ’åºï¼ˆé»˜è®¤ Trueï¼‰
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼ˆé»˜è®¤ Trueï¼‰
        """
        self.enable = enable
        self.enable_cache = enable_cache
        self.model = None
        self.model_name = model_name or "BAAI/bge-reranker-base"
        self.cache_ttl = 7200  # é»˜è®¤2å°æ—¶
        self._redis_client = None
        self._memory_cache = {}  # å†…å­˜ç¼“å­˜ä½œä¸ºåå¤‡
        
        if self.enable:
            try:
                import os
                
                # é…ç½® Hugging Face é•œåƒï¼ˆå¿…é¡»åœ¨å¯¼å…¥ sentence_transformers ä¹‹å‰è®¾ç½®ï¼‰
                # ä¼˜å…ˆä½¿ç”¨ Settings ä¸­çš„é…ç½®ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡
                from app.core.config import get_settings
                settings = get_settings()
                hf_mirror = settings.hf_endpoint or os.getenv("HF_ENDPOINT", "")
                if hf_mirror:
                    # è®¾ç½®å¤šä¸ªå¯èƒ½çš„ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿é•œåƒç”Ÿæ•ˆ
                    os.environ["HF_ENDPOINT"] = hf_mirror
                    os.environ["HUGGINGFACE_HUB_CACHE"] = os.getenv("HUGGINGFACE_HUB_CACHE", "")
                    logger.info(f"ä½¿ç”¨ Hugging Face é•œåƒ: {hf_mirror}")
                
                # åˆå§‹åŒ–ç¼“å­˜
                if self.enable_cache:
                    self.cache_ttl = settings.rerank_cache_ttl
                    # å°è¯•è¿æ¥ Redisï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if settings.redis_url:
                        try:
                            import redis.asyncio as redis
                            self._redis_client = redis.from_url(settings.redis_url, decode_responses=True)
                            logger.info("âœ… é‡æ’åºç¼“å­˜ï¼šä½¿ç”¨ Redis")
                        except Exception as e:
                            logger.warning(f"âš ï¸ Redis è¿æ¥å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜ç¼“å­˜: {e}")
                            self._redis_client = None
                    else:
                        logger.info("â„¹ï¸ é‡æ’åºç¼“å­˜ï¼šä½¿ç”¨å†…å­˜ç¼“å­˜ï¼ˆRedis æœªé…ç½®ï¼‰")
                
                # åœ¨è®¾ç½®ç¯å¢ƒå˜é‡åå†å¯¼å…¥
                from sentence_transformers import CrossEncoder
                
                logger.info(f"ğŸ”„ åˆå§‹åŒ–é‡æ’åºæ¨¡å‹: {self.model_name}")
                self.model = CrossEncoder(self.model_name)
                logger.info("âœ… é‡æ’åºæ¨¡å‹åŠ è½½å®Œæˆ")
            except ImportError:
                logger.warning(
                    "âš ï¸ sentence-transformers æœªå®‰è£…ï¼Œé‡æ’åºåŠŸèƒ½å·²ç¦ç”¨ã€‚"
                    "è¯·è¿è¡Œ: pip install sentence-transformers"
                )
                self.enable = False
            except Exception as e:
                error_msg = str(e)
                if "SSL" in error_msg or "huggingface.co" in error_msg:
                    logger.warning(
                        f"âš ï¸ æ— æ³•ä» Hugging Face ä¸‹è½½æ¨¡å‹ï¼ˆç½‘ç»œé—®é¢˜ï¼‰ï¼Œé‡æ’åºåŠŸèƒ½å·²ç¦ç”¨ã€‚\n"
                        f"è§£å†³æ–¹æ¡ˆï¼š\n"
                        f"1. è®¾ç½®ç¯å¢ƒå˜é‡ HF_ENDPOINT=https://hf-mirror.comï¼ˆä½¿ç”¨é•œåƒï¼‰\n"
                        f"2. æˆ–è®¾ç½® ENABLE_RERANK=false ç¦ç”¨é‡æ’åº\n"
                        f"3. æˆ–é…ç½®ä»£ç†åé‡è¯•"
                    )
                else:
                    logger.error(f"âŒ é‡æ’åºæ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
                self.enable = False
    
    def _generate_cache_key(self, query: str, chunk_texts: list[str]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ä½¿ç”¨æŸ¥è¯¢å’Œæ–‡æ¡£æ–‡æœ¬çš„å“ˆå¸Œå€¼ç”Ÿæˆç¼“å­˜é”®
        content = f"{query}|||{','.join(chunk_texts)}"
        key_hash = hashlib.md5(content.encode('utf-8')).hexdigest()
        return f"rerank:{key_hash}"
    
    async def _get_cached_scores(self, cache_key: str) -> list[float] | None:
        """ä»ç¼“å­˜è·å–é‡æ’åºåˆ†æ•°"""
        if not self.enable_cache:
            return None
        
        try:
            # ä¼˜å…ˆä½¿ç”¨ Redis
            if self._redis_client:
                try:
                    cached = await self._redis_client.get(cache_key)
                    if cached:
                        scores = json.loads(cached)
                        logger.debug(f"é‡æ’åºç¼“å­˜å‘½ä¸­ï¼ˆRedisï¼‰: {cache_key}")
                        return scores
                except Exception as e:
                    logger.debug(f"Redis ç¼“å­˜è¯»å–å¤±è´¥: {e}")
            
            # åå¤‡ï¼šä½¿ç”¨å†…å­˜ç¼“å­˜
            if cache_key in self._memory_cache:
                cached_data = self._memory_cache[cache_key]
                scores = cached_data.get("scores")
                logger.debug(f"é‡æ’åºç¼“å­˜å‘½ä¸­ï¼ˆå†…å­˜ï¼‰: {cache_key}")
                return scores
        except Exception as e:
            logger.debug(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        return None
    
    async def _set_cached_scores(self, cache_key: str, scores: list[float]) -> None:
        """ç¼“å­˜é‡æ’åºåˆ†æ•°"""
        if not self.enable_cache:
            return
        
        try:
            # ä¼˜å…ˆä½¿ç”¨ Redis
            if self._redis_client:
                try:
                    await self._redis_client.setex(
                        cache_key,
                        self.cache_ttl,
                        json.dumps(scores)
                    )
                    logger.debug(f"é‡æ’åºç¼“å­˜å†™å…¥ï¼ˆRedisï¼‰: {cache_key}, TTL: {self.cache_ttl}s")
                    return
                except Exception as e:
                    logger.debug(f"Redis ç¼“å­˜å†™å…¥å¤±è´¥: {e}")
            
            # åå¤‡ï¼šä½¿ç”¨å†…å­˜ç¼“å­˜ï¼ˆé™åˆ¶å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡ºï¼‰
            if len(self._memory_cache) < 1000:  # æœ€å¤šç¼“å­˜1000æ¡
                self._memory_cache[cache_key] = {
                    "scores": scores,
                    "timestamp": __import__("time").time()
                }
                logger.debug(f"é‡æ’åºç¼“å­˜å†™å…¥ï¼ˆå†…å­˜ï¼‰: {cache_key}")
            else:
                # ç®€å•çš„ LRUï¼šåˆ é™¤æœ€æ—§çš„æ¡ç›®
                if self._memory_cache:
                    oldest_key = min(
                        self._memory_cache.keys(),
                        key=lambda k: self._memory_cache[k].get("timestamp", 0)
                    )
                    del self._memory_cache[oldest_key]
                    self._memory_cache[cache_key] = {
                        "scores": scores,
                        "timestamp": __import__("time").time()
                    }
        except Exception as e:
            logger.debug(f"ç¼“å­˜å†™å…¥å¤±è´¥: {e}")
    
    async def rerank_async(
        self,
        query: str,
        chunks: list[Any],
        top_k: int | None = None
    ) -> list[Any]:
        """
        å¼‚æ­¥é‡æ’åºï¼ˆæ”¯æŒç¼“å­˜ï¼‰ã€‚
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            chunks: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆRetrievedChunk å¯¹è±¡ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡ï¼ŒNone è¡¨ç¤ºè¿”å›æ‰€æœ‰ç»“æœ
        
        Returns:
            é‡æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        if not self.enable or not self.model or not chunks:
            return chunks
        
        if len(chunks) <= 1:
            return chunks
        
        try:
            # æ„å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹
            chunk_texts = [chunk.text for chunk in chunks]
            pairs = [[query, text] for text in chunk_texts]
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cache_key = self._generate_cache_key(query, chunk_texts)
            cached_scores = await self._get_cached_scores(cache_key)
            
            if cached_scores is not None:
                # ä½¿ç”¨ç¼“å­˜çš„åˆ†æ•°
                scores = cached_scores
                logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„é‡æ’åºåˆ†æ•°: {len(scores)} æ¡")
            else:
                # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆCross-Encoder ä¼šåŒæ—¶ç¼–ç æŸ¥è¯¢å’Œæ–‡æ¡£ï¼‰
                scores = self.model.predict(pairs)
                # ç¼“å­˜åˆ†æ•°
                await self._set_cached_scores(cache_key, scores.tolist() if hasattr(scores, 'tolist') else list(scores))
            
            # å°†åˆ†æ•°æ·»åŠ åˆ° chunks å¹¶é‡æ–°æ’åº
            reranked_chunks = []
            for chunk, score in zip(chunks, scores):
                # æ›´æ–°åˆ†æ•°ä¸ºé‡æ’åºåˆ†æ•°
                reranked_chunk = replace(
                    chunk,
                    score=float(score),
                    source_type="reranked"
                )
                reranked_chunks.append(reranked_chunk)
            
            # æŒ‰é‡æ’åºåˆ†æ•°é™åºæ’åˆ—
            reranked_chunks.sort(key=lambda c: c.score, reverse=True)
            
            logger.debug(
                f"é‡æ’åºå®Œæˆ: {len(chunks)} æ¡ç»“æœï¼Œ"
                f"åˆ†æ•°èŒƒå›´: {min(scores):.4f} - {max(scores):.4f}"
            )
            
            # è¿”å› Top-K
            if top_k is not None:
                return reranked_chunks[:top_k]
            return reranked_chunks
            
        except Exception as e:
            logger.error(f"é‡æ’åºå¤±è´¥: {e}", exc_info=True)
            # å¤±è´¥æ—¶è¿”å›åŸå§‹ç»“æœ
            return chunks
    
    def rerank(
        self,
        query: str,
        chunks: list[Any],
        top_k: int | None = None
    ) -> list[Any]:
        """
        åŒæ­¥é‡æ’åºï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œå†…éƒ¨è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬ï¼‰ã€‚
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            chunks: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆRetrievedChunk å¯¹è±¡ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡ï¼ŒNone è¡¨ç¤ºè¿”å›æ‰€æœ‰ç»“æœ
        
        Returns:
            é‡æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        import asyncio
        try:
            # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼‰
                return self._rerank_sync(query, chunks, top_k)
            else:
                # å¦‚æœäº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œå¯ä»¥è¿è¡Œå¼‚æ­¥ç‰ˆæœ¬
                return loop.run_until_complete(self.rerank_async(query, chunks, top_k))
        except RuntimeError:
            # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨åŒæ­¥ç‰ˆæœ¬
            return self._rerank_sync(query, chunks, top_k)
    
    def _rerank_sync(self, query: str, chunks: list[Any], top_k: int | None = None) -> list[Any]:
        """åŒæ­¥é‡æ’åºï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼Œç”¨äºå…¼å®¹ï¼‰"""
        if not self.enable or not self.model or not chunks:
            return chunks
        
        if len(chunks) <= 1:
            return chunks
        
        try:
            pairs = [[query, chunk.text] for chunk in chunks]
            scores = self.model.predict(pairs)
            
            reranked_chunks = []
            for chunk, score in zip(chunks, scores):
                reranked_chunk = replace(
                    chunk,
                    score=float(score),
                    source_type="reranked"
                )
                reranked_chunks.append(reranked_chunk)
            
            reranked_chunks.sort(key=lambda c: c.score, reverse=True)
            
            if top_k is not None:
                return reranked_chunks[:top_k]
            return reranked_chunks
            
        except Exception as e:
            logger.error(f"é‡æ’åºå¤±è´¥: {e}", exc_info=True)
            return chunks
    
    def is_enabled(self) -> bool:
        """æ£€æŸ¥é‡æ’åºæ˜¯å¦å¯ç”¨ä¸”å¯ç”¨ã€‚"""
        return self.enable and self.model is not None

