import os
import sys
import argparse
import asyncio
import json
import logging
from pathlib import Path
import time
from typing import Dict

# --- 1. è·¯å¾„è¡¥ä¸ ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

# --- 2. å¯¼å…¥ä¾èµ– ---
from rag.ingestion import DocumentIngestor
# ğŸŒŸ æ–°å¢å¯¼å…¥ï¼šç”¨äºé‡å»ºæ•°æ®åº“è¿æ¥
from langchain_chroma import Chroma
from vectorDB.Chroma import embedding_model

# --- 3. é…ç½®å¸¸é‡ä¸æ—¥å¿— ---
STATE_FILE = os.path.join(project_root, "ingestion_state.json")
SUPPORTED_EXTENSIONS = {'.pdf', '.docx', '.doc', '.xlsx', '.xls', '.html', '.htm', '.txt', '.md'}

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_state() -> Dict[str, float]:
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_state(state: Dict[str, float]):
    try:
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")


async def main():
    parser = argparse.ArgumentParser(description="RAG æ–‡æ¡£æ‰¹é‡å…¥åº“å·¥å…·")
    parser.add_argument("dir", help="æ–‡æ¡£æ‰€åœ¨çš„ç›®å½•è·¯å¾„")
    parser.add_argument("--mode", choices=["full", "update"], default="update",
                        help="æ¨¡å¼ï¼šfull (å…¨é‡é‡å»º) / update (å¢é‡æ›´æ–°)")
    args = parser.parse_args()

    source_dir = Path(args.dir)
    if not source_dir.exists():
        logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return

    # --- 4. åˆå§‹åŒ– ---
    logger.info("ğŸ—ï¸  æ­£åœ¨åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨...")
    ingestor = DocumentIngestor()

    # --- 5. æ¨¡å¼å¤„ç† ---
    state = {}
    if args.mode == "full":
        logger.warning("âš ï¸  [å…¨é‡æ¨¡å¼] æ­£åœ¨æ¸…ç©ºå‘é‡æ•°æ®åº“...")
        try:
            # 1. åˆ é™¤æ—§é›†åˆ
            ingestor.vector_db.delete_collection()
            logger.info("âœ… æ•°æ®åº“å·²æ¸…ç©ºã€‚")

            # ğŸŒŸ å…³é”®ä¿®å¤ï¼šåˆ é™¤åå¿…é¡»é‡æ–°è¿æ¥/åˆ›å»ºé›†åˆï¼Œå¦åˆ™åŸæ¥çš„å¯¹è±¡ä¼šå¤±æ•ˆ
            logger.info("ğŸ”„ æ­£åœ¨é‡æ–°åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
            ingestor.vector_db = Chroma(
                persist_directory="./chroma_store",
                collection_name="industrial_qa_docs",
                embedding_function=embedding_model
            )

        except Exception as e:
            logger.error(f"æ¸…ç©ºæ•°æ®åº“å¤±è´¥: {e}")

        if os.path.exists(STATE_FILE):
            os.remove(STATE_FILE)
    else:
        state = load_state()
        logger.info(f"ğŸ”„ [å¢é‡æ¨¡å¼] åŠ è½½äº† {len(state)} æ¡å†å²è®°å½•")

    # --- 6. æ‰«æ ---
    logger.info(f"ğŸ“‚ æ­£åœ¨æ‰«æç›®å½•: {source_dir}")
    files_to_process = []

    for file_path in source_dir.rglob("*"):
        if file_path.is_file() and file_path.suffix.lower() in SUPPORTED_EXTENSIONS:
            abs_path = str(file_path.absolute())
            current_mtime = file_path.stat().st_mtime

            should_process = False
            reason = ""

            if args.mode == "full":
                should_process = True
            elif abs_path not in state:
                should_process = True
                reason = "æ–°æ–‡ä»¶"
            elif current_mtime > state[abs_path]:
                should_process = True
                reason = "å†…å®¹æ›´æ–°"

            if should_process:
                files_to_process.append((file_path, abs_path, current_mtime, reason))

    logger.info(f"ğŸ“Š æ‰«æå®Œæˆ: å‘ç° {len(files_to_process)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")

    # --- 7. æ‰§è¡Œ ---
    success_count = 0
    fail_count = 0

    for i, (file_path, abs_path, mtime, reason) in enumerate(files_to_process):
        prefix = f"[{i + 1}/{len(files_to_process)}]"
        logger.info(f"{prefix} å¤„ç†ä¸­ ({reason}): {file_path.name}")

        try:
            # è°ƒç”¨å¤„ç†é€»è¾‘ (session ä¼  None)
            report = await ingestor.ingest_file(file_path, session=None)

            if report.status == "success":
                logger.info(f"   âœ… æˆåŠŸ | ID: {str(report.document_id)[:8]}... | Chunks: {report.chunk_count}")
                state[abs_path] = mtime
                save_state(state)
                success_count += 1
            else:
                logger.error(f"   âŒ å¤±è´¥ | åŸå› : {report.error}")
                fail_count += 1

        except Exception as e:
            logger.error(f"   âŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
            fail_count += 1

    logger.info("=" * 40)
    logger.info(f"ğŸ‰ æ‰¹å¤„ç†ç»“æŸ | æˆåŠŸ: {success_count} | å¤±è´¥: {fail_count}")


if __name__ == "__main__":
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())